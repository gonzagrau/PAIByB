{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6be447a",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# Trabajo Práctico 1: estimación de ruido y denoising\n",
    "\n",
    "## Procesamiento Avanzado de Imágenes en Biomedicina y Biología\n",
    "\n",
    "### Segundo Cuatrimestre 2024\n",
    "\n",
    "<table>\n",
    "      <tr>\n",
    "        <th>Alumnos</th>\n",
    "        <th>Legajos</th>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>\n",
    "          Bajlec, Ivo<br>\n",
    "          Grau, Gonzalo Andrés<br>\n",
    "          Neira, Lucas Matias\n",
    "        </td>\n",
    "        <td>\n",
    "          62175<br>\n",
    "          62259<br>\n",
    "          61750<br>\n",
    "        </td>\n",
    "      </tr>\n",
    "    </table>\n",
    "\n",
    "**Docente**: Roberto Sebastián Tomás\n",
    "\n",
    "**Fecha de entrega**: 02/09/2024\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481db26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:30:56.557291Z",
     "start_time": "2024-09-01T23:30:52.918453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports necesarios para el resto del archivo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from fft_analysis import *\n",
    "from snr_estimation import *\n",
    "from img_roi_analyzer import *\n",
    "from stat_noise_estimation import load_stat_data, stat_noise_reconstruction, hist_noise_reconstruction\n",
    "from test_wavelet import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7058f4262eac5b",
   "metadata": {},
   "source": [
    "## Objetivos del trabajo\n",
    "Mediante el siguiente trabajo, se buscará mejorar la calidad de imágenes biomédicas inherentemente ruidosas. Para ello, se aplicarán técnicas de estimación de ruido y denoising, incluyendo estimaciones estadísticas a partir de regiones de interés homogéneas (ROI, por la sigla en inglés *region of interest*), análisis en el dominio frecuencial, y descomposición por transformadas de wavelets. Luego, se evaluarán los resultados obtenidos mediante métricas relacionadas al *signal to noise ratio* (SNR) de las reconstrucciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e3a2e5",
   "metadata": {},
   "source": [
    "## Aclaración sobre el formato del informe\n",
    "\n",
    "Debido a que dedicamos archivos .py y .ipynb específicos para cada subítem del trabajo, para mayor modularización y prolijidad, optamos por no incluir gran parte del código fuente en el informe. En todo momento, se hará referencia a los archivos utilizados para generar las figuras, los cuales están disponibles en el repositorio de este informe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c1eb0beca3146",
   "metadata": {},
   "source": [
    "## Primera parte: análisis y reconstrucción de ruido mediante procesamiento de ROIs\n",
    "\n",
    "En la siguiente sección, se desarrollará un análisis de las imágenes contenidas en la carpeta PAIByB-1, muestreando adecuadamente sus segmentos ruidosos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba36e2ba1e74ff",
   "metadata": {},
   "source": [
    "#### 1.1, 1.2: Escriban un código en Python que les permita trazar una linea y un rectángulo de dimensiones BxH en diferentes porciones de en una imagen, calcule histograma, varianza y valor esperado de las imágenes obtenidas en el inciso anterior, y guarde los resultados.\n",
    "\n",
    "Para esta parte del proyecto, se desarrolló una interfaz gráfica con PyQT6 que permite escoger una imagen desde un directorio indicado por el usuario, seleccionar una ROI en forma de línea o de rectángulo. A partir de esto, se puede visualizar el perfil de la imágen como una señal de intensidad vs. distancia en pixeles (promediando por sobre las filas para el caso de la ROI rectangular). Finalmente, se procede a guardar en un archivo dedicado (dentro de la carpeta `infosaves`, con la extesión `.json`) los siguientes valores:\n",
    "- Media de intensidad de gris en la ROI\n",
    "- Forma y ubicación de la ROI seleccionada\n",
    "- Desviación estándar\n",
    "- Nombre de la imagen de proveniencia\n",
    "\n",
    "Al mismo tiempo, se guardó un histograma calculado por sobre las intensidades de grisis en el segmento, en formato `.csv`\n",
    "\n",
    "![image.png](imagenes_informe/foto_gui.png)\n",
    "\n",
    "Para acceder al código fuente, ver el archivo `img_roi_analyzer.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8d81b",
   "metadata": {},
   "source": [
    "#### 1.3: Reconstrucción de ruido en base a análisis estadístico de segmentos\n",
    "\n",
    "Haciendo uso de las características extraídas con la GUI del ítem anterior, se intentó reconstruir el ruido de las imágenes de la carpeta `PAIByB-1` mediante el análisis estadístico de ROI seleccionadas manualmente. Las funciones para realizar este análisis se encuentran en el archivo `stat_noise_estimation.py`, y las estimaciones sobre las imágenes de `PAIByB-1` se encuentran en el notebook `a01_stat_estimation.ipynb`. \n",
    "\n",
    "A continuación, se procede a visualizar las estimaciones obtenidas mediante análisis de media y varianza, simulando al ruido mediante un distribución normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a221b866af9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:43:44.622168Z",
     "start_time": "2024-09-01T23:43:44.564199Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_image_comp_plot(original_img_dir: str, \n",
    "                          reconstructed_img_dir: str, \n",
    "                          title: str='Reconstruccion') -> None:\n",
    "    \"\"\"\n",
    "    Plots original images against reconstruted ones, \n",
    "    Args:\n",
    "        dir_original (str): path for original images\n",
    "        dir_reconstructed (str): path for reconstructions\n",
    "    \"\"\"\n",
    "    original_files = os.listdir(original_img_dir)\n",
    "    reconstructed_files = os.listdir(reconstructed_img_dir)\n",
    "\n",
    "    original_rec_dict = {original_file: reconstructed_file for original_file in original_files\n",
    "                         for reconstructed_file in reconstructed_files\n",
    "                         if original_file.split('.')[0] in reconstructed_file}\n",
    "\n",
    "    fig, axs = plt.subplots(len(original_files), 2, figsize=(10, 20))\n",
    "    i = 0\n",
    "\n",
    "    for original, reconstructed in original_rec_dict.items():\n",
    "        img_original = cv2.imread(os.path.join(original_img_dir, original), cv2.IMREAD_GRAYSCALE)\n",
    "        img_reconstructed = cv2.imread(os.path.join(reconstructed_img_dir, reconstructed), cv2.IMREAD_GRAYSCALE)\n",
    " \n",
    "        axs[i, 0].imshow(img_original, cmap='gray', vmin=0, vmax=255)\n",
    "        axs[i, 0].set_title(f'Imagen original {original}')\n",
    "        axs[i, 1].imshow(img_reconstructed, cmap='gray', vmin=0, vmax=255)\n",
    "        axs[i, 1].set_title(title)\n",
    "        axs[i, 0].axis('off')\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d68e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recolectamos la información de las slices obtenidas con la GUI\n",
    "datadir = 'infosaves'\n",
    "data_dict, hist_dict = load_stat_data(datadir)\n",
    "\n",
    "# Estimamos el ruido\n",
    "noise_dir = 'PAIByB-1'\n",
    "output_dir = 'noise_estimation/stat_estimation'\n",
    "\n",
    "stat_noise_reconstruction(data_dict, noise_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5e28c",
   "metadata": {},
   "source": [
    "Luego, mediante análisis del histograma, se ajustó una distribución normal a cada figuras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558309a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'noise_estimation/hist_estimation'\n",
    "hist_noise_reconstruction(hist_dict, noise_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee25e0f",
   "metadata": {},
   "source": [
    "#### 1.4 Análisis de ruido a través de la Transformada de Fourier en 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f626454",
   "metadata": {},
   "source": [
    "Para la estimación de ruido, en primer lugar se llevará a cabo un análisis de la magnitud espectral de dos imágenes de `PAIByB-1` para una mejor lectura del NB. En particular, se trabajará con `Noise-1.tif` y`Noise-4.tif`. \n",
    "\n",
    "Las función para llevar a cabo este análisis se llama `cr8FFTimgsPlots` la cual se encuentra en el archivo `fft_analysis.py`. Para ver una mejor demostración de la aplicación de esta función, se sugiere revisar el NB `ff_analysis.ipynb`.\n",
    "\n",
    "La magnitud espectral se analizará con imágenes en 2 y 3 dimensiones para una mejor compresión. Esto es con el fin de poder comparar la 'altura' del nivel de ruido entre `Noise-1.tif` y `Noise-4.tif`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb7524",
   "metadata": {},
   "source": [
    "![alt text](noise_estimation/fourier_estimation/Noise-1_fourier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e6563",
   "metadata": {},
   "source": [
    "![alt text](noise_estimation/fourier_estimation/Noise-4_fourier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87e01e",
   "metadata": {},
   "source": [
    "Comparando la magnitud de cada imagen, se puede decir que el ruido de `Noise-1.tif` está en el orden de 80 db como máximo, mientras que para `Noise-4.tif` el ruido se encuentra en el orden de más de 90 dB como máximo. Observando las imagenes, claramente hay una correlación entre la cantidad de ruido en cada una y su magnitud espectral, siendo mayor en el caso de `Noise-4.tif`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebba7a",
   "metadata": {},
   "source": [
    "#### 1.5: estimación de ruido con Wavelets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495ed0b",
   "metadata": {},
   "source": [
    "Para la estimación de ruido mediante la descomposición de wavelet, se optó por realizar una recomposiscion de la imagen mediante las componentes de ruido de alta frecuencia. \n",
    "Esto se logra seleccionando un nivel de descomposición a tavez de la funcion `wavedec2`  de la librería `Pywavelets`. Luego una vez obtenidos todos los componentes de ese nivel, se modifica a 0 el componente de baja frecuencia. Así la imagen reconstruida\n",
    "es una combinancion del ruido de alta frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e994f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ruido = 'PAIByB-1'\n",
    "path_estim_wav = 'noise_estimation/wavelet_estimation'\n",
    "multi_image_comp_plot(path_ruido, path_estim_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e1745",
   "metadata": {},
   "source": [
    "#### 1.6: Cuantificación del denoising\n",
    "\n",
    "Para cuantificar la eficiencia del denoising, se calcularon el peak-SNR y el SSIM. Estas funciones fueron implementadas en `snr_estimation.py`, utilizando la implementación de SSIM disponible en scikit-image. El propio código para obtener estos resultados se encuentra en `snr_metrics.ipynb`. A continuación, se muestran los resultados obtenidos para cada caso:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42bc20c",
   "metadata": {},
   "source": [
    "- Método de reconstrucción de ruido: **Varianza Local**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a29374cfe4c9bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:03:09.925004Z",
     "start_time": "2024-09-01T23:03:09.876889Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_dir = 'metrics'\n",
    "noise_stat_df = pd.read_csv(os.path.join(metrics_dir, 'noise_stat.csv'), index_col=0)\n",
    "noise_stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a543678",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "881b889d",
   "metadata": {},
   "source": [
    "- Método de reconstrucción de ruido: **Estimación Estadística del Histograma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593f4e365eb92278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:03:35.720510Z",
     "start_time": "2024-09-01T23:03:35.681478Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_hist_df = pd.read_csv(os.path.join(metrics_dir, 'noise_hist.csv'), index_col=0)\n",
    "noise_hist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb5fb8",
   "metadata": {},
   "source": [
    "- Método de reconstrucción de ruido: **Transformada Wavelets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fec806fb6c85ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:20:46.000025Z",
     "start_time": "2024-09-01T23:20:45.960318Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_wavelet_df = pd.read_csv(os.path.join(metrics_dir, 'noise_wavelet.csv'), index_col=0)\n",
    "noise_wavelet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bcf38376db9dab",
   "metadata": {},
   "source": [
    "## Segunda parte: denoising aplicado a imágenes biomédicas\n",
    "\n",
    "En esta sección, utilizaremos estimaciones del ruido en las imágenes de la carpeta PAIByB-2 para poder así extraer estas componentes y conservar únicamente la información relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73d18da6d3d299",
   "metadata": {},
   "source": [
    "#### 2.1 Estimación de ruido por análisis estadístico de ROIs\n",
    "Haciendo uso de la interfaz creada para el subitem 1.1, se extrajeron segmentos rectangulares homogéneos del fondo de las imágenes presentes en `PAIByB-2`, para posteriormente analizarlas y simular su ruido mediante una distribución normal. Para ello, se utilizaron las funciones definidas en `stat_noise_estimation.py`, y se ejecutó el análisis en `a02_pies_stat_noise.ipynb`. \n",
    "\n",
    "A continuación, se muestran los resultados obtenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67169928a74abe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:36:52.886510Z",
     "start_time": "2024-09-01T23:36:50.872096Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reconstruimos el ruido con media y varianza\n",
    "noise_dir = 'PAIByB-2'\n",
    "output_dir = 'noise_estimation/stat_estimation'\n",
    "image_dir = 'PAIByB-2'\n",
    "stat_noise_reconstruction(data_dict, noise_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e150ad",
   "metadata": {},
   "source": [
    "A partir de las reconstrucción de ruido para cada imagen, es posible observar una correlación bastante amplia entre el ruido observable en la imagen original y la reconstrucción realizada a partir de estimación estadística."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba8d5d363d355f",
   "metadata": {},
   "source": [
    "#### 2.2 Métodos de denoising espacial\n",
    "\n",
    "Para reducir el ruido en las imágenes de `PAIByB-2` mediante filtros \"clásicos\", se utilizaron las funciones del módulo `cv2` en el archivo `a02_spatial_denoising.ipynb`. En particular, para los kernels gaussianos, se utilizó como desviación estándar la obtenida en la estimación del ruido del subitem anterior para cada imagen correspondiente. Se obtuvo el siguiente resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9555baf56f74df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:37:02.942144Z",
     "start_time": "2024-09-01T23:36:59.743278Z"
    }
   },
   "outputs": [],
   "source": [
    "datadir = 'infosaves'\n",
    "data_dict, hist_dict = load_stat_data(datadir)\n",
    "paths = os.listdir(image_dir)\n",
    "fig, axs = plt.subplots(len(paths), 3, figsize=(20, 20))\n",
    "\n",
    "for i, image_path in enumerate(paths):\n",
    "    raw_name = image_path.split('.')[0]\n",
    "    sigma = data_dict[raw_name]['desv_est']\n",
    "    img = cv2.imread(os.path.join(image_dir, image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    gauss_image = cv2.GaussianBlur(img, (5, 5), sigmaX=sigma, sigmaY=sigma)\n",
    "    median_image = cv2.medianBlur(img, 5)\n",
    "    \n",
    "    axs[i, 0].imshow(img, vmin=0, vmax=255, cmap='gray')\n",
    "    axs[i, 0].set_title(f'Imagen original {raw_name}')\n",
    "    axs[i, 1].imshow(gauss_image, cmap='gray', vmin=0, vmax=255)\n",
    "    axs[i, 1].set_title(f'Imagen filtrada con Gauss')\n",
    "    axs[i, 2].imshow(median_image, cmap='gray', vmin=0, vmax=255)\n",
    "    axs[i, 2].set_title(f'Imagen filtrada con filtro de mediana')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b33411e",
   "metadata": {},
   "source": [
    "#### 2.3.1 Estimación de ruido y denoising a través de la Transformada de Fourier en 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bcab88",
   "metadata": {},
   "source": [
    "Para la estimación de ruido, en primer lugar se llevará a cabo un análisis de la magnitud espectral de dos imágenes de `PAIByB-2` para una mejor lectura del NB. En particular, se trabajará con `Pie2-1.tif` y`Pie2-4.tif`. La magnitud espectral se analizará con imágenes en 2 y 3 dimensiones para una mejor compresión. Esto es con el fin de poder comparar la 'altura' del nivel de ruido entre `Pie2-1.tif` y `Pie2-4.tif`.\n",
    "\n",
    "Se utilizará la función para llevar a cabo este análisis se llama `cr8FFTimgsPlots` la cual se encuentra en el archivo `fft_analysis.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efbca62",
   "metadata": {},
   "source": [
    "![alt text](noise_estimation/fourier_estimation/Pie2-1_sp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88359c",
   "metadata": {},
   "source": [
    "![alt text](noise_estimation/fourier_estimation/Pie2-4_sp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85840679",
   "metadata": {},
   "source": [
    "Observando los gráficos en 3D, es posible observar que existe un aumento de la magnitud espectral para bajas frecuencias. Comparando la magnitud de las altas frecuencias entre `Pie2-1.tif` y `Pie2-4.tif`, es en el caso de `Pie2-4.tif` donde el 'piso' tiene una magnitud mayor (70 y 85 dB, respectivamente). Esto quiere decir que, efectivamente, la imagen `Pie2-4.tif` es más ruidosa que `Pie2-1.tif`.\n",
    "\n",
    "Ahora bien, para llevar a cabo el denoising de las imágenes, decidimos aplicar *máscaras*, matrices con valores 0 y 1, las cuales, multiplicadas a la FFT de la imagen original, ocultan frecuencias espaciales características que, a la hora de reconstruir la FFT, se observen cambios en imagen.\n",
    "\n",
    "La intención de construir estas máscaras es separar el ruido de los objetos de interés. Para crear estas máscaras, se parte de la magnitud espectral de cada imagen y se eligen dos valores umbrales, uno superior y otro inferior. El umbral inferior corresponderá a la magnitud que comparte el ruido de alta frecuencia; el umbral superior corresponderá a la magnitud que comparte el ruido de baja frecuencia.\n",
    "\n",
    "Para `Pie2-1.tif`:\n",
    "- Umbral inferior: 60 dB\n",
    "- Umbral superior: 130 dB\n",
    "\n",
    "Para `Pie2-4.tif`:\n",
    "- Umbral inferior: 85 dB\n",
    "- Umbral superior: 135 dB\n",
    "\n",
    "Las función para llevar a cabo este análisis se llama `cr8FFTNoiseEstimPlots` la cual se encuentra en el archivo `fft_analysis.py`. Para ver una mejor demostración de la aplicación de esta función, se sugiere revisar el NB `fft_analysis.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55715b40",
   "metadata": {},
   "source": [
    "![alt text](noise_estimation/fourier_estimation/Pie2-1_fourier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da3f80",
   "metadata": {},
   "source": [
    "![alt text](noise_estimation/fourier_estimation/Pie2-4_fourier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb0a12",
   "metadata": {},
   "source": [
    "Cada una de los figuras anteriores muestra el ruido estimado para cada imagen. Está claro nuevamente que, la imagen `Pie2-4.tif` posee mayor cantidad de ruido que `Pie2-1.tif`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ceaa4",
   "metadata": {},
   "source": [
    "Una vez determinados los umbrales para cada imagen, se aplica una máscara inversa a la creada anteriormente: nuestro algoritmo de denoising crea una máscara para ocultar el ruido de baja y alta frecuencia y conservar las frecuencias pertenecientes al objeto en estudio.\n",
    "\n",
    "Las función para llevar a cabo este análisis se llama `cr8FFTDenoisingPlots` la cual se encuentra en el archivo `fft_analysis.py`. Para ver una mejor demostración de la aplicación de esta función, se sugiere revisar el NB `fft_analysis.ipynb`.\n",
    "\n",
    "Los resultados son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b09df1d0808609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:42:35.891026Z",
     "start_time": "2024-09-01T23:42:34.259916Z"
    }
   },
   "outputs": [],
   "source": [
    "origin_dir = 'PAIByB-2'\n",
    "filtered_dir = 'denoised_img/fourier_denoising'\n",
    "multi_image_comp_plot(origin_dir, filtered_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df30105",
   "metadata": {},
   "source": [
    "Luego de aplicar el denoising, la imagen resultante posee una mejora considerable con respecto a su imagen original. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2d9e2",
   "metadata": {},
   "source": [
    "#### 2.3.2 Estimación de ruido y denoising a través de la Transformada de Wavelets en 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f3487",
   "metadata": {},
   "source": [
    "Para la reacilación de la estimación de ruido del ruido de los archivos de la carpeta `PAIByB-2` se realizó un procedimiento analogo al del punto 1.5. Extrayendo solo las comonetes de ruido de alta frecuencia. Sin, embargo aqui se puede ver que wavelets, no es un método presiso para la estimación del ruido.Esto se debe a que al querer estimarlo sin contexto sobre la imagen, se pueden también tomar los detalles de alta freciuencia como lo son los bordes de la imagen. Se podría realizar un analisis de varios niveles, sin embargo siempre se arrastra algo de los componentes de borde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df9aea1ac7f6fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:45:42.292166Z",
     "start_time": "2024-09-01T23:45:40.698063Z"
    }
   },
   "outputs": [],
   "source": [
    "origin_dir = 'PAIByB-2'\n",
    "estim_noise_dir = 'noise_estimation/wavelet_estimation'\n",
    "multi_image_comp_plot(origin_dir, estim_noise_dir, title='Ruido estimado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbceed5a",
   "metadata": {},
   "source": [
    "Para lo que es el denoising, se realizó una técnica similar a la estimación del ruido. Lo que se hizo fue poder seleccionar que componentes de alta frecuencia tomar además del de baja frecuencia. De esta forma, se pueden eliminar cada componente de un nivel particular. Este procedimiento es usuario dependiente,  recae en prueba y error, ya que se debe seleccionar el nivel y el componente a incluir.Para las imagenes a continuación se presenta la descomposición en 2 niveles tomando la componente de baja frecuencia y las componentes de alta frecuencia del nivel 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35f2f1b721796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T23:45:04.414045Z",
     "start_time": "2024-09-01T23:45:02.900862Z"
    }
   },
   "outputs": [],
   "source": [
    "origin_dir = 'PAIByB-2'\n",
    "filtered_dir = 'denoised_img/wavelet_denoising'\n",
    "multi_image_comp_plot(origin_dir, filtered_dir, title='Denoised')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f138276eb179c9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a37b88f1ff179ea",
   "metadata": {},
   "source": [
    "#### 2.4 Métricas de SNR en denoising\n",
    "\n",
    "A continuación, se muestran los resultados obtenidos en `snr_metrics.ipynb` para la cuantificación del denosing con cada método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285bcdc840339ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T00:31:56.744464Z",
     "start_time": "2024-09-02T00:31:56.707892Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_dir = 'metrics'\n",
    "methods = ['wavelet', 'fourier', 'gauss', 'median']\n",
    "dfs = []\n",
    "for method in methods:\n",
    "    method_df = pd.read_csv(os.path.join(metrics_dir, f\"denoise_{method}.csv\"), index_col=0)\n",
    "    method_df.rename(mapper=lambda x, m=method: f\"{x} ({m})\", axis='columns', inplace=True)\n",
    "    dfs.append(method_df)\n",
    "\n",
    "ssim_df = pd.concat([dfs[i][f'SSIM ({method})'] for i, method in enumerate(methods)], axis=1)\n",
    "psnr_df = pd.concat([dfs[i][f'PSNR ({method})'] for i, method in enumerate(methods)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e03593eb9a003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T00:32:12.649602Z",
     "start_time": "2024-09-02T00:32:12.614925Z"
    }
   },
   "outputs": [],
   "source": [
    "psnr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3efa79d723434e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T00:32:04.810950Z",
     "start_time": "2024-09-02T00:32:04.772982Z"
    }
   },
   "outputs": [],
   "source": [
    "ssim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd373466fb795594",
   "metadata": {},
   "source": [
    "#### 2.5 Analisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d8797",
   "metadata": {},
   "source": [
    "En general se puede decir que los filtrso gauseanos y de mediana al ser filtros pasa bajo, tienen el efecto de suavizar la imagen quitado detalles finos como lo son los bordes, pero eliminando ruido de alta frecuencia. A su vez, la trasformada de wavelets, tiene una ventaja que se puede manipular que componentes conservar, perdiendo una menor cantidad de detalles de alta frecuencia, sin embargo es notorio el suavizado (por lo menos con el método aaplicado de nivel 2). Para este trabajo se trabajo creando filtros pasa banda de fourier, viendo los limites a ojo. A pesar de lapoca automatización, para la gan mayoria de las imagenes este fue el mejor filtro, preservando detalles finos e eliminando el ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f913915806adfae",
   "metadata": {},
   "source": [
    "## Parte 3: aumento de contraste\n",
    "\n",
    "Para esta sección, se utilizaron los códigos del módulo `cv2` para ecualizar global y localmente el histograma de las imágenes mejoradas por el método de denoising con transformada de Fourier. En primer lugar, veremos el resultado de aplicar una ecualización global: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d84b915f4bcc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T00:49:10.575614Z",
     "start_time": "2024-09-02T00:49:09.418877Z"
    }
   },
   "outputs": [],
   "source": [
    "image_dir = 'denoised_img/fourier_denoising'\n",
    "eq_hist_dir = 'eq_hist_global_img'\n",
    "multi_image_comp_plot(image_dir, eq_hist_dir, 'Ecualizacion global')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78805d7db0dddfc1",
   "metadata": {},
   "source": [
    "A continuación, vemos el resultado de aplicar un ecualizado con CLAHE para `clipLimit=2.0`, `tileGridSize=(8x8)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2d33ce06ca5be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T00:49:31.926453Z",
     "start_time": "2024-09-02T00:49:30.712420Z"
    }
   },
   "outputs": [],
   "source": [
    "image_dir = 'denoised_img/fourier_denoising'\n",
    "eq_hist_dir = 'clahe_images'\n",
    "multi_image_comp_plot(image_dir, eq_hist_dir, 'Ecualizacion CLAHE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e33a375d41f411",
   "metadata": {},
   "source": [
    "Para entender mejor el funcionamiento del algoritmo de CLAHE, corrimos el siguiente código haciendo una pequeña gridsearch sobre los hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed7d4ddbd253b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T01:02:29.073068Z",
     "start_time": "2024-09-02T01:02:26.276820Z"
    }
   },
   "outputs": [],
   "source": [
    "cliplimits = [2**i for i in range(2, 6)]\n",
    "grid_sides = [2**i for i in range(3, 7)]\n",
    "raw_img = cv2.imread('denoised_img/fourier_denoising/Pie2-2_fourier.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(cliplimits), ncols=len(grid_sides), figsize=(20, 20))\n",
    "\n",
    "for i, clip in enumerate(cliplimits):\n",
    "    for j, grid_side in enumerate(grid_sides):\n",
    "        clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=(grid_side, grid_side))\n",
    "        img_clahe = clahe.apply(raw_img)\n",
    "        axs[i, j].imshow(img_clahe, cmap='gray', vmin=0, vmax=255)\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].set_title(f'{clip=}, {grid_side=}')\n",
    "\n",
    "fig.suptitle('Gridsearch de hiperparámetro para CLAHE', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8a453",
   "metadata": {},
   "source": [
    "A simple vista, puede notarse que al aumentar el clip limit se *reduce* el contraste general de la imagen. Por otro lado, aumentar el grid size realza los bordes, actuando en forma análoga a un filtro pasa altos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3acd1ae8e47db",
   "metadata": {},
   "source": [
    "## Bonus: herramienta para visualizar el cálculo de SNR mediante el histograma\n",
    "\n",
    "Para aquellos casos en los alcanza con analizar el histograma para diferenciar una banda de intensidades de nivel de gris como \"señal\" y al resto como \"ruido\", se puede calcular la SNR de la imagen como\n",
    "\n",
    "\\begin{equation}\n",
    "    SNR = \\frac{ \\mu_{Señal} - \\mu_{Fondo} }{\\sigma_{Fondo}}\n",
    "\\end{equation}\n",
    "\n",
    "donde $\\mu$ y $\\sigma$ indican respectivamente valro medio y desviación estándar en cada barra.\n",
    "\n",
    "Para automatizar este proceso, se diseñó una interfaz gráfica que permite escoger una imágen y seleccionar dinámicamente el segmento \"señal\" desde el histograma, analizando cómo la imagen cambia al eliminar la banda ruidosa\n",
    "\n",
    "![image](imagenes_informe/gui_snr.png)\n",
    "\n",
    "De esta manera, se puede visualizar instantáneamente la diferencia entre las bandas, y la información presente en cada una. El código fuente se encuentra en el archivo `hist_SNR.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
